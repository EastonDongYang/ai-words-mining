#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„OpenAI promptæ•ˆæœ
"""

import sys
import os
from datetime import datetime

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from config import Config
from src.openai_analyzer import OpenAIAnalyzer

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    return [
        {
            'name': 'AI Code Assistant',
            'description': 'An AI-powered coding assistant that uses retrieval-augmented generation (RAG) to help developers write better code. Features include multimodal code analysis, prompt engineering assistance, and automated documentation generation.',
            'categories': ['Developer Tools', 'AI Assistant']
        },
        {
            'name': 'Smart Content Creator',
            'description': 'AI tool for content creators that enables zero-shot learning for video editing, supports synthetic media generation, and offers real-time collaboration features for distributed teams.',
            'categories': ['Content Creation', 'AI Tools']
        },
        {
            'name': 'Voice Clone Studio',
            'description': 'Advanced voice cloning technology using few-shot learning techniques. Supports emotional voice synthesis, cross-lingual voice conversion, and offers edge computing deployment for privacy-focused applications.',
            'categories': ['Audio AI', 'Voice Technology']
        },
        {
            'name': 'Vision AI Platform',
            'description': 'Computer vision platform featuring foundation models for object detection, supports federated learning for privacy-preserving training, and includes explainable AI features for model interpretability.',
            'categories': ['Computer Vision', 'AI Platform']
        },
        {
            'name': 'Text Analytics Pro',
            'description': 'Natural language processing tool with advanced semantic search capabilities, supports agentic AI workflows, and features automated reasoning for complex text analysis tasks.',
            'categories': ['NLP', 'Text Analysis']
        }
    ]

def test_new_prompt():
    """æµ‹è¯•æ–°çš„promptæ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–åçš„OpenAI prompt...")
    
    # æ£€æŸ¥é…ç½®
    config = Config()
    if not config.OPENAI_API_KEY:
        print("âŒ è¯·è®¾ç½®OpenAI API Key")
        return False
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = OpenAIAnalyzer()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = create_test_data()
    
    print(f"ğŸ“Š ä½¿ç”¨ {len(test_data)} ä¸ªæµ‹è¯•å·¥å…·è¿›è¡Œåˆ†æ...")
    
    try:
        # åˆ†ææµ‹è¯•æ•°æ®
        results = analyzer.analyze_and_extract(test_data)
        
        if results:
            print(f"\nâœ… æˆåŠŸæå– {len(results)} ä¸ªæ¦‚å¿µæ€§è¯æ±‡:")
            print("="*80)
            
            for i, word_data in enumerate(results, 1):
                print(f"\nğŸ” #{i}. {word_data['word']}")
                print(f"   åˆ†ç±»: {word_data['category']}")
                print(f"   å®šä¹‰: {word_data['definition']}")
                print(f"   é‡è¦æ€§: {word_data['importance']}")
                print(f"   è¶‹åŠ¿æ½œåŠ›: {word_data['trend_potential']}/10")
                print(f"   å•†ä¸šä»·å€¼: {word_data['business_value']}")
                print(f"   æ–°å…´æ¦‚å¿µ: {'âœ…' if word_data.get('is_emerging', False) else 'âŒ'}")
                print(f"   æ’ååˆ†æ•°: {word_data.get('ranking_score', 0):.1f}")
                print(f"   ä¸Šä¸‹æ–‡: {word_data['context']}")
            
            # åˆ†æç»“æœè´¨é‡
            print("\nğŸ“ˆ ç»“æœè´¨é‡åˆ†æ:")
            emerging_count = sum(1 for w in results if w.get('is_emerging', False))
            high_trend_count = sum(1 for w in results if w.get('trend_potential', 5) >= 7)
            high_business_count = sum(1 for w in results if w.get('business_value', 'medium') == 'high')
            
            print(f"   - æ–°å…´æ¦‚å¿µ: {emerging_count}/{len(results)} ({emerging_count/len(results)*100:.1f}%)")
            print(f"   - é«˜è¶‹åŠ¿æ½œåŠ› (â‰¥7): {high_trend_count}/{len(results)} ({high_trend_count/len(results)*100:.1f}%)")
            print(f"   - é«˜å•†ä¸šä»·å€¼: {high_business_count}/{len(results)} ({high_business_count/len(results)*100:.1f}%)")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“åç§°
            product_names = ['chatgpt', 'claude', 'midjourney', 'gpt-4', 'dall-e', 'stable diffusion']
            found_products = [w['word'] for w in results if any(p in w['word'].lower() for p in product_names)]
            
            if found_products:
                print(f"\nâš ï¸ å‘ç°äº§å“åç§°: {found_products}")
            else:
                print(f"\nâœ… æ²¡æœ‰å‘ç°äº§å“åç§°ï¼Œè¿‡æ»¤æ•ˆæœè‰¯å¥½")
            
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            categories = {}
            for word_data in results:
                category = word_data['category']
                categories[category] = categories.get(category, 0) + 1
            
            print(f"\nğŸ“Š æŒ‰ç±»åˆ«ç»Ÿè®¡:")
            for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
                print(f"   - {category}: {count} ä¸ª")
            
            return True
            
        else:
            print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•è¯æ±‡")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def compare_with_old_results():
    """ä¸æ—§ç‰ˆæœ¬ç»“æœå¯¹æ¯”"""
    print("\nğŸ’¡ ä¼˜åŒ–æ•ˆæœå¯¹æ¯”:")
    print("ğŸ”´ æ—§ç‰ˆæœ¬é—®é¢˜:")
    print("   - æå–äº§å“åç§° (ChatGPTã€Claudeã€Midjourneyç­‰)")
    print("   - åŒ…å«ç‰ˆæœ¬å· (V6ã€XLã€Proç­‰)")
    print("   - ç¼ºä¹è¶‹åŠ¿ä»·å€¼è¯„ä¼°")
    print("   - ä¸é€‚åˆGoogle Trendsåˆ†æ")
    
    print("\nğŸŸ¢ æ–°ç‰ˆæœ¬æ”¹è¿›:")
    print("   - ä¸“æ³¨æ¦‚å¿µæ€§è¯æ±‡ï¼Œè¿‡æ»¤äº§å“åç§°")
    print("   - æ·»åŠ è¶‹åŠ¿æ½œåŠ›è¯„ä¼° (1-10åˆ†)")
    print("   - æ·»åŠ å•†ä¸šä»·å€¼è¯„ä¼°")
    print("   - è¯†åˆ«æ–°å…´æ¦‚å¿µæ ‡å¿—")
    print("   - é€‚åˆGoogle Trendsåˆ†æå’Œå»ºç«™")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æµ‹è¯•ä¼˜åŒ–åçš„OpenAI promptæ•ˆæœ...")
    print("="*60)
    
    try:
        success = test_new_prompt()
        
        if success:
            compare_with_old_results()
            
            print("\nâœ… æµ‹è¯•å®Œæˆ!")
            print("\nğŸ¯ ç°åœ¨ç³»ç»Ÿä¼šæå–:")
            print("   - çœŸæ­£çš„æ–°å…´æ¦‚å¿µ (å¦‚ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆã€å¤šæ¨¡æ€åˆ†æ)")
            print("   - æŠ€æœ¯æ–¹æ³•è®º (å¦‚ï¼šé›¶æ ·æœ¬å­¦ä¹ ã€è”é‚¦å­¦ä¹ )")
            print("   - åº”ç”¨åœºæ™¯æ–°è¯ (å¦‚ï¼šè¾¹ç¼˜è®¡ç®—éƒ¨ç½²ã€éšç§ä¿æŠ¤è®­ç»ƒ)")
            print("   - è¡Œä¸šå‘å±•è¶‹åŠ¿ (å¦‚ï¼šä»£ç†AIå·¥ä½œæµã€å¯è§£é‡ŠAI)")
            
            print("\nğŸ’¡ å»ºè®®:")
            print("   1. å®šæœŸæ›´æ–°äº§å“åç§°è¿‡æ»¤åˆ—è¡¨")
            print("   2. æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´è¶‹åŠ¿æ½œåŠ›é˜ˆå€¼")
            print("   3. è€ƒè™‘æ·»åŠ æ›´å¤šè¯„ä¼°ç»´åº¦")
            print("   4. å®šæœŸéªŒè¯Google Trendsæœç´¢æ•ˆæœ")
            
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
        return False
    
    return True

if __name__ == "__main__":
    main() 