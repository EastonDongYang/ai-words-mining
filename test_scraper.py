#!/usr/bin/env python3
"""
æµ‹è¯•ç½‘é¡µçˆ¬å–åŠŸèƒ½
"""

import sys
import os
import json

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from config import Config
from src.web_scraper import AIToolsScraper

def test_scraper():
    """æµ‹è¯•çˆ¬å–åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ç½‘é¡µçˆ¬å–åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        scraper = AIToolsScraper()
        
        # æµ‹è¯•ç½‘é¡µçˆ¬å–
        print(f"ğŸ•·ï¸ å¼€å§‹çˆ¬å–: {scraper.config.TARGET_URL}")
        
        # ä½¿ç”¨fallbackæ–¹æ³•å…ˆæµ‹è¯•
        tools_data = scraper.scrape_with_requests(scraper.config.TARGET_URL)
        
        if tools_data:
            print(f"âœ… æˆåŠŸçˆ¬å–åˆ° {len(tools_data)} ä¸ªå·¥å…·")
            print("\nğŸ“‹ ç¤ºä¾‹æ•°æ®:")
            for i, tool in enumerate(tools_data[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"{i+1}. {tool['name']}")
                print(f"   æè¿°: {tool['description'][:100]}...")
                print(f"   åˆ†ç±»: {tool.get('categories', [])}")
                print()
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open('test_scraped_data.json', 'w', encoding='utf-8') as f:
                json.dump(tools_data, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ° test_scraped_data.json")
            return True
            
        else:
            print("âŒ æ²¡æœ‰çˆ¬å–åˆ°æ•°æ®")
            return False
            
    except Exception as e:
        print(f"âŒ çˆ¬å–æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = test_scraper()
    sys.exit(0 if success else 1) 