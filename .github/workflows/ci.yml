name: AI Words Scraper CI/CD

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]
  schedule:
    # 每天UTC时间02:00运行 (北京时间10:00)
    - cron: '0 2 * * *'

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - name: 检出代码
      uses: actions/checkout@v4
    
    - name: 设置Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: 升级pip
      run: |
        python -m pip install --upgrade pip
    
    - name: 安装依赖
      run: |
        pip install -r requirements.txt
    
    - name: 安装Playwright浏览器
      run: |
        python -m playwright install chromium
    
    - name: 运行测试
      run: |
        python -m pytest test_*.py -v
    
    - name: 测试Crawl4AI导入
      run: |
        python -c "from src.crawl4ai_scraper import Crawl4AIScraper; print('✅ Crawl4AIScraper导入成功')"
    
    - name: 测试基本功能
      run: |
        python -c "
        import asyncio
        from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
        
        async def test():
            config = BrowserConfig(headless=True)
            run_config = CrawlerRunConfig(wait_for_timeout=2000)
            
            async with AsyncWebCrawler(config=config) as crawler:
                result = await crawler.arun(url='https://example.com', config=run_config)
                print(f'✅ 测试成功: {result.success}')
                print(f'内容长度: {len(result.markdown)} 字符')
        
        asyncio.run(test())
        "

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master'
    
    steps:
    - name: 检出代码
      uses: actions/checkout@v4
    
    - name: 设置Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: 安装依赖
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: 安装Playwright浏览器
      run: |
        python -m playwright install chromium
    
    - name: 运行爬虫 (测试模式)
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        GOOGLE_SHEETS_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
      run: |
        python main.py --mock-mode
    
    - name: 创建发布包
      run: |
        mkdir -p dist
        cp -r src dist/
        cp requirements.txt dist/
        cp config.py dist/
        cp main.py dist/
        cp README.md dist/
        
    - name: 上传构建产物
      uses: actions/upload-artifact@v3
      with:
        name: ai-words-scraper
        path: dist/

  scheduled-run:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - name: 检出代码
      uses: actions/checkout@v4
    
    - name: 设置Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: 安装依赖
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: 安装Playwright浏览器
      run: |
        python -m playwright install chromium
    
    - name: 运行定时爬虫任务
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        GOOGLE_SHEETS_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
      run: |
        python main.py --scheduled
    
    - name: 上传日志
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: scraper-logs
        path: logs/ 