#!/usr/bin/env python3
"""
æµ‹è¯•å¤‡ä»½è¾“å‡ºåŠŸèƒ½çš„è„šæœ¬
ç”¨äºéªŒè¯å½“Google Sheetså¤±è´¥æ—¶çš„å¤‡ç”¨è¾“å‡ºæ–¹æ³•
"""

import sys
import os
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.mock_web_scraper import MockWebScraper
from src.openai_analyzer import OpenAIAnalyzer
from src.data_processor import DataProcessor
from config import Config

def test_backup_outputs():
    """æµ‹è¯•å¤‡ä»½è¾“å‡ºåŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¤‡ä»½è¾“å‡ºåŠŸèƒ½...")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„AIWordsMiningSystemç±»æ¥æµ‹è¯•å¤‡ä»½åŠŸèƒ½
        class MockAIWordsMiningSystem:
            def __init__(self):
                self.config = Config()
                self.start_time = datetime.now()
                self.stats = {
                    'scraped_tools': 8,
                    'extracted_words': 12,
                    'processed_words': 10,
                    'sheets_updated': False,
                    'warnings': ['Google Sheets connection failed', 'Used mock data']
                }
            
            def create_backup_outputs(self, words_data, summary_data):
                """Create backup outputs when Google Sheets fails"""
                backup_methods = []
                
                try:
                    # 1. Enhanced local file backup
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    backup_filename = f"ai_words_backup_{timestamp}.json"
                    
                    backup_data = {
                        'timestamp': timestamp,
                        'summary': summary_data,
                        'words': words_data,
                        'execution_stats': self.stats,
                        'total_words': len(words_data),
                        'execution_time': str(datetime.now() - self.start_time)
                    }
                    
                    import json
                    with open(backup_filename, 'w', encoding='utf-8') as f:
                        json.dump(backup_data, f, indent=2, ensure_ascii=False)
                    
                    print(f"âœ… Created local backup: {backup_filename}")
                    backup_methods.append(f"Local backup: {backup_filename}")
                    
                    # 2. Create human-readable summary
                    summary_filename = f"ai_words_summary_{timestamp}.txt"
                    with open(summary_filename, 'w', encoding='utf-8') as f:
                        f.write("ğŸ‰ AI Words Mining System - Execution Summary\n")
                        f.write("=" * 50 + "\n\n")
                        
                        f.write(f"ğŸ“… Execution Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"â±ï¸ Duration: {datetime.now() - self.start_time}\n")
                        f.write(f"ğŸŒ Target URL: {self.config.TARGET_URL}\n\n")
                        
                        f.write("ğŸ“Š Statistics:\n")
                        f.write(f"  - Tools Scraped: {self.stats['scraped_tools']}\n")
                        f.write(f"  - Words Extracted: {self.stats['extracted_words']}\n")
                        f.write(f"  - Words Processed: {self.stats['processed_words']}\n")
                        f.write(f"  - Google Sheets Updated: {'âœ…' if self.stats['sheets_updated'] else 'âŒ'}\n\n")
                        
                        f.write("ğŸ“ Extracted Words:\n")
                        f.write("-" * 30 + "\n")
                        for i, word in enumerate(words_data, 1):
                            f.write(f"{i}. {word.get('word', 'N/A')}\n")
                            f.write(f"   Category: {word.get('category', 'N/A')}\n")
                            f.write(f"   Definition: {word.get('definition', 'N/A')}\n")
                            f.write(f"   Context: {word.get('context', 'N/A')}\n")
                            f.write(f"   Importance: {word.get('importance', 'N/A')}\n\n")
                        
                        if self.stats.get('warnings'):
                            f.write("âš ï¸ Warnings:\n")
                            f.write("-" * 30 + "\n")
                            for warning in self.stats['warnings']:
                                f.write(f"  - {warning}\n")
                            f.write("\n")
                        
                        f.write("ğŸ”§ Backup Methods Used:\n")
                        f.write("-" * 30 + "\n")
                        for method in backup_methods:
                            f.write(f"  - {method}\n")
                    
                    print(f"âœ… Created readable summary: {summary_filename}")
                    backup_methods.append(f"Readable summary: {summary_filename}")
                    
                    # 3. Create email content file
                    email_content = f"""
ğŸ‰ AI Words Mining System - Results Report

â° Execution Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ•·ï¸ Tools Analyzed: {self.stats['scraped_tools']}
ğŸ§  Words Extracted: {self.stats['extracted_words']}
âš™ï¸ Words Processed: {self.stats['processed_words']}
ğŸ“Š Google Sheets: âŒ (Failed - using backup methods)

ğŸ“ Top Extracted Words:
{self.format_words_for_email(words_data[:5])}

ğŸ”§ System Information:
- Execution Time: {datetime.now() - self.start_time}
- Target URL: {self.config.TARGET_URL}
- Backup Methods: {', '.join(backup_methods)}

ğŸ“§ Email would be sent to: {self.config.NOTIFICATION_EMAIL}

Best regards,
AI Words Mining System
                    """
                    
                    email_filename = f"email_backup_{timestamp}.txt"
                    with open(email_filename, 'w', encoding='utf-8') as f:
                        f.write(email_content)
                    
                    print(f"âœ… Created email content: {email_filename}")
                    backup_methods.append(f"Email content: {email_filename}")
                    
                    # 4. Create GitHub-style artifacts
                    artifacts_dir = "artifacts"
                    os.makedirs(artifacts_dir, exist_ok=True)
                    
                    # Copy backup file to artifacts
                    import shutil
                    if os.path.exists(backup_filename):
                        shutil.copy2(backup_filename, os.path.join(artifacts_dir, backup_filename))
                    
                    # Create summary file
                    summary_file = os.path.join(artifacts_dir, "execution_summary.md")
                    with open(summary_file, 'w', encoding='utf-8') as f:
                        f.write(f"""# AI Words Mining Execution Summary

## ğŸ“Š Execution Statistics
- **Start Time**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
- **End Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Duration**: {datetime.now() - self.start_time}
- **Tools Scraped**: {self.stats['scraped_tools']}
- **Words Extracted**: {self.stats['extracted_words']}
- **Words Processed**: {self.stats['processed_words']}

## ğŸ“ Extracted Words
{self.format_words_for_markdown(words_data)}

## âš ï¸ Warnings
{chr(10).join(f"- {warning}" for warning in self.stats.get('warnings', []))}

## ğŸ”§ Backup Methods
{chr(10).join(f"- {method}" for method in backup_methods)}
""")
                    
                    print(f"âœ… Created GitHub artifacts in {artifacts_dir}/")
                    backup_methods.append(f"GitHub artifacts: {artifacts_dir}/")
                    
                    return backup_methods
                    
                except Exception as e:
                    print(f"âŒ Backup creation failed: {e}")
                    return []
            
            def format_words_for_email(self, words_data):
                """Format words data for email display"""
                if not words_data:
                    return "No words extracted"
                
                formatted = []
                for i, word in enumerate(words_data, 1):
                    formatted.append(f"{i}. {word.get('word', 'N/A')} ({word.get('category', 'N/A')})")
                    if word.get('definition'):
                        formatted.append(f"   Definition: {word.get('definition', 'N/A')}")
                    formatted.append("")  # Empty line
                
                return "\n".join(formatted)
            
            def format_words_for_markdown(self, words_data):
                """Format words data for markdown display"""
                if not words_data:
                    return "No words extracted"
                
                formatted = ["| Word | Category | Definition |", "|------|----------|------------|"]
                for word in words_data:
                    formatted.append(f"| {word.get('word', 'N/A')} | {word.get('category', 'N/A')} | {word.get('definition', 'N/A')} |")
                
                return "\n".join(formatted)
        
        # 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
        print("1ï¸âƒ£ ç”Ÿæˆæµ‹è¯•æ•°æ®...")
        mock_scraper = MockWebScraper()
        tools_data = mock_scraper.scrape_ai_tools(5)
        print(f"âœ… ç”Ÿæˆäº† {len(tools_data)} ä¸ªæ¨¡æ‹Ÿå·¥å…·")
        
        # 2. æ¨¡æ‹ŸOpenAIåˆ†æ
        print("\n2ï¸âƒ£ æ¨¡æ‹ŸOpenAIåˆ†æ...")
        config = Config()
        if config.OPENAI_API_KEY:
            try:
                analyzer = OpenAIAnalyzer()
                extracted_words = analyzer.analyze_tools_batch(tools_data[:3])
                print(f"âœ… æˆåŠŸæå–äº† {len(extracted_words)} ä¸ªæ–°è¯æ±‡")
            except Exception as e:
                print(f"âš ï¸ OpenAIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
                extracted_words = [
                    {'word': 'Test Word 1', 'category': 'AI Technology', 'definition': 'Test definition 1', 'context': 'Test context', 'importance': 'high'},
                    {'word': 'Test Word 2', 'category': 'Machine Learning', 'definition': 'Test definition 2', 'context': 'Test context', 'importance': 'medium'}
                ]
        else:
            print("âš ï¸ æœªé…ç½®OpenAI APIï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            extracted_words = [
                {'word': 'Mock Word 1', 'category': 'AI Technology', 'definition': 'Mock definition 1', 'context': 'Mock context', 'importance': 'high'},
                {'word': 'Mock Word 2', 'category': 'Machine Learning', 'definition': 'Mock definition 2', 'context': 'Mock context', 'importance': 'medium'}
            ]
        
        # 3. æ•°æ®å¤„ç†
        print("\n3ï¸âƒ£ å¤„ç†æ•°æ®...")
        processor = DataProcessor()
        processed_result = processor.process_extracted_words(extracted_words)
        processed_words = processed_result.get('words', [])
        summary_data = processed_result.get('summary', {})
        print(f"âœ… å¤„ç†äº† {len(processed_words)} ä¸ªè¯æ±‡")
        
        # 4. æµ‹è¯•å¤‡ä»½è¾“å‡º
        print("\n4ï¸âƒ£ æµ‹è¯•å¤‡ä»½è¾“å‡º...")
        system = MockAIWordsMiningSystem()
        backup_methods = system.create_backup_outputs(processed_words, summary_data)
        
        # 5. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        print("\n5ï¸âƒ£ éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶...")
        files_to_check = [
            'ai_words_backup_*.json',
            'ai_words_summary_*.txt',
            'email_backup_*.txt',
            'artifacts/execution_summary.md'
        ]
        
        import glob
        for pattern in files_to_check:
            matches = glob.glob(pattern)
            if matches:
                print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {', '.join(matches)}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶: {pattern}")
        
        print("\n" + "=" * 50)
        print("ğŸ‰ å¤‡ä»½è¾“å‡ºåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        print("âœ… æ‰€æœ‰å¤‡ä»½æ–¹æ³•éƒ½æ­£å¸¸å·¥ä½œ")
        print(f"ğŸ“ ç”Ÿæˆçš„å¤‡ä»½æ–¹æ³•: {len(backup_methods)} ç§")
        for method in backup_methods:
            print(f"  - {method}")
        
        print("\nğŸ“§ é‚®ä»¶é…ç½®:")
        print(f"  - æ”¶ä»¶äºº: {config.NOTIFICATION_EMAIL}")
        print(f"  - å‘ä»¶äºº: ai-words-mining@gmail.com")
        print("  - æ³¨æ„: éœ€è¦é…ç½®EMAIL_PASSWORDç¯å¢ƒå˜é‡æ‰èƒ½å®é™…å‘é€é‚®ä»¶")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_backup_outputs()
    sys.exit(0 if success else 1) 